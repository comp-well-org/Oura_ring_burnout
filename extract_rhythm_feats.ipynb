{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.stats import skew, kurtosis\n",
    "import copy\n",
    "from rhythm_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hourly data\n",
    "file_path = '../Studies/oura_feats_bin01_23_hourly.csv'\n",
    "hourly_data = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'hour' to datetime and set it as the index\n",
    "hourly_data['hour'] = pd.to_datetime(hourly_data['hour'])\n",
    "hourly_data.set_index('hour', inplace=True)\n",
    "\n",
    "# Interpolate missing values linearly\n",
    "hourly_data.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Forward fill and backward fill\n",
    "hourly_data.fillna(method='ffill', inplace=True)\n",
    "hourly_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Identify and remove participants or days with excessive missing data\n",
    "missing_data_threshold = 0.5  # 50% threshold\n",
    "grouped_data = hourly_data.groupby([hourly_data.index.date, 'participant_id']).apply(\n",
    "    lambda group: group.isna().mean()\n",
    ")\n",
    "excessive_missing_data = grouped_data[grouped_data > missing_data_threshold].dropna(how='all')\n",
    "\n",
    "# Handle days with excessive missing data (if any)\n",
    "hourly_data.reset_index(inplace=True)\n",
    "\n",
    "# Prepare the final datasets\n",
    "# Dataset with imputed values\n",
    "# hourly_data.to_csv('/path/to/amed_clean_hour_template.csv')\n",
    "\n",
    "# Dataset with missing values imputed as zeros\n",
    "hour_data_zeros = hourly_data.fillna(0)\n",
    "# hour_data_zeros.to_csv('/path/to/amed_clean_hour_zeros.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_window_oura(data, window_length):\n",
    "    if window_length > 21:\n",
    "        print('Invalid Length')\n",
    "        return\n",
    "\n",
    "    window_l = window_length  # In days\n",
    "    window_Delta = timedelta(days=window_l)\n",
    "    grouped = data.groupby(by=['participant_id'])\n",
    "    # print(grouped.mean())\n",
    "    data_window = []\n",
    "\n",
    "    for participant_id, group in grouped:\n",
    "        \n",
    "        df = group.copy()\n",
    "        df['hour'] = pd.to_datetime(df['hour'])\n",
    "        df.sort_values(by='hour', inplace=True)\n",
    "\n",
    "        start = df['hour'].iloc[0]\n",
    "        end = start + window_Delta\n",
    "\n",
    "        # Selecting data within the window\n",
    "        data_values = df[(df['hour'] >= start) & (df['hour'] < end)]\n",
    "        # # Check if the length of data matches the window length\n",
    "        # if len(data_values) != window_l * 24:\n",
    "        #     continue\n",
    "\n",
    "        # Add back the participant_id\n",
    "        data_values['participant_id'] = participant_id\n",
    "        data_window.append(data_values)\n",
    "    \n",
    "    # Concatenating all participant data into a single DataFrame\n",
    "    data_window = pd.concat(data_window, ignore_index=True)\n",
    "    \n",
    "    return data_window\n",
    "\n",
    "data7 = get_time_window_oura(hourly_data, 7)\n",
    "data14 = get_time_window_oura(hourly_data, 14)\n",
    "data21 = get_time_window_oura(hourly_data, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M10(data, value_col, hour_col):\n",
    "    m10_list = []\n",
    "    for _, day_data in data.groupby(data[hour_col].dt.date):\n",
    "        m10 = 0\n",
    "        # if len(day_data) >= 10:  # Only consider days with at least 10 data points\n",
    "        sorted_day_data = day_data.sort_values(by=hour_col)\n",
    "        data_array = sorted_day_data[value_col].values\n",
    "        for i in range(len(data_array)-9):\n",
    "            m10 = max(m10, sum(data_array[i:i+10])/10)\n",
    "        m10_list.append(m10)\n",
    "    return np.nanmean(m10_list) if m10_list else np.nan\n",
    "\n",
    "def L5(data, value_col, hour_col):\n",
    "    l5_list = []\n",
    "    for _, day_data in data.groupby(data[hour_col].dt.date):\n",
    "        l5 = 0\n",
    "        # if len(day_data) >= 5:  # Only consider days with at least 5 data points\n",
    "        sorted_day_data = day_data.sort_values(by=hour_col)\n",
    "        data_array = sorted_day_data[value_col].values\n",
    "        for i in range(len(data_array)-4):\n",
    "            l5 = max(l5, sum(data_array[i:i+5])/5)\n",
    "        l5_list.append(l5)\n",
    "    return np.nanmean(l5_list) if l5_list else np.nan\n",
    "\n",
    "def get_template(data, value_col, hour_col='hour', window_l=5):\n",
    "    template = []\n",
    "    for hour in range(24):\n",
    "        hourly_data = data[data[hour_col].dt.hour == hour]\n",
    "        if not hourly_data.empty:\n",
    "            val_mean = hourly_data[value_col].mean()\n",
    "        else:\n",
    "            val_mean = np.nan  # No data for this hour\n",
    "        template.append({'hour': hour, value_col: val_mean})\n",
    "\n",
    "    return pd.DataFrame(template)\n",
    "\n",
    "\n",
    "\n",
    "def deviation_from_template(data, value_col, hour_col='hour'):\n",
    "    template = get_template(data, value_col, hour_col)\n",
    "    df_result = []\n",
    "\n",
    "    for date, day_data in data.groupby(data[hour_col].dt.date):\n",
    "        hourly_diff = []\n",
    "\n",
    "        for hour in range(24):\n",
    "            template_val = template.loc[template['hour'] == hour, value_col].values[0]\n",
    "            if not np.isnan(template_val) and hour in day_data[hour_col].dt.hour.values:\n",
    "                day_val = day_data[day_data[hour_col].dt.hour == hour][value_col].values[0]\n",
    "                hourly_diff.append(template_val - day_val)\n",
    "\n",
    "        if hourly_diff:  # Proceed if there are any non-NaN differences\n",
    "            df = pd.DataFrame({\n",
    "                'mean_diff': [np.mean(hourly_diff)],\n",
    "                'median_diff': [np.median(hourly_diff)],\n",
    "                'sd_diff': [np.std(hourly_diff)],\n",
    "                'skew': [skew(hourly_diff)],\n",
    "                'kurtosis': [kurtosis(hourly_diff)]\n",
    "            })\n",
    "            df_result.append(df)\n",
    "\n",
    "    return pd.concat(df_result, ignore_index=True) if df_result else pd.DataFrame()\n",
    "\n",
    "\n",
    "def fit_cosinor(df, value_col, hour_col, periods):\n",
    "    # Copy and prepare the data\n",
    "    signal = df.copy()\n",
    "    signal.rename(columns={value_col: 'y'}, inplace=True)\n",
    "    \n",
    "    # Convert datetime to numeric (e.g., hours since start)\n",
    "    start_time = signal[hour_col].min()\n",
    "    signal['x'] = (signal[hour_col] - start_time).dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "    variables = {}\n",
    "\n",
    "    for pi in periods:\n",
    "        if pi < 8:\n",
    "            continue\n",
    "\n",
    "        model, stats, params, xtest, ytest = cosinor.fit_me(signal['x'].values, signal['y'].values, period=pi, plot=False)\n",
    "\n",
    "        mesor = params['mesor']\n",
    "        Amp = params['amplitude']\n",
    "        phi = params['acrophase']\n",
    "        rss = stats['p_reject']\n",
    "\n",
    "        variables[value_col + '_' + str(pi) + 'mesor'] = mesor\n",
    "        variables[value_col + '_' + str(pi) + 'amp'] = Amp\n",
    "        variables[value_col + '_' + str(pi) + 'phi'] = phi\n",
    "        variables[value_col + '_' + str(pi) + 'p_reject'] = rss\n",
    "\n",
    "    return variables\n",
    "\n",
    "def cal_rhythm_features(data):\n",
    "    grouped = data.groupby(by=['participant_id'])\n",
    "    columns = ['avg_hr', 'std_hr', 'Sleep Stage Sum']\n",
    "    rhythm_feats = []\n",
    "    for group in grouped:\n",
    "        \n",
    "        df = copy.deepcopy(group[1])\n",
    "        ID = group[0]\n",
    "        curr_fea_df = []\n",
    "        \n",
    "        for col_val in columns:\n",
    "            curr_window = copy.deepcopy(df[[col_val,'hour']])\n",
    "            \n",
    "            M10H = M10(curr_window, col_val, 'hour')\n",
    "            L5H = L5(curr_window, col_val, 'hour')\n",
    "            AMP = (M10H-L5H)/(M10H+L5H)\n",
    "            DVT = deviation_from_template(curr_window, col_val, 'hour')\n",
    "            \n",
    "            period_list = [8,16,20, 22, 27, 28, 32, 36, 64, 72, 128]\n",
    "            PSD = power_spectral_density(curr_window[col_val], period_list)\n",
    "            \n",
    "            cosinor_value = fit_cosinor(curr_window, col_val, 'hour', period_list) \n",
    "            fea_dict = {'M10':[M10H],'L5':[L5H], 'AMP':[AMP]}\n",
    "            fea_dict.update(PSD)\n",
    "            fea_dict.update(cosinor_value)\n",
    "            fea_dict2 = {col_val+'_'+k: v for k,v in fea_dict.items()}\n",
    "            DVT = DVT.mean().to_dict()\n",
    "            fea_df = pd.DataFrame(data={**fea_dict2, **DVT})\n",
    "            if len(curr_fea_df) == 0:\n",
    "                curr_fea_df = fea_df\n",
    "            else:\n",
    "                curr_fea_df = pd.concat((curr_fea_df,fea_df), axis=1)\n",
    "        curr_fea_df['ID'] = ID\n",
    "        \n",
    "        if len(rhythm_feats) == 0:\n",
    "            rhythm_feats = curr_fea_df\n",
    "        else:\n",
    "            rhythm_feats = pd.concat((rhythm_feats,curr_fea_df), axis=0) \n",
    "    rhythm_feats.reset_index(inplace=True, drop=True)\n",
    "    return rhythm_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhythm_7days = cal_rhythm_features(data7)\n",
    "rhythm_14days = cal_rhythm_features(data14)\n",
    "rhythm_21days = cal_rhythm_features(data21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhythm_7days.reset_index(inplace=True, drop=True)\n",
    "feat_type = 'template'\n",
    "save_path = '../Studies/BIN_features/rhythm_features/'\n",
    "rhythm_7days.to_csv(save_path + 'rhythm7days'+feat_type+'.csv', index=False)  \n",
    "rhythm_14days.to_csv(save_path + 'rhythm14days'+feat_type+'.csv', index=False)  \n",
    "rhythm_21days.to_csv(save_path + 'rhythm21days'+feat_type+'.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = data7.groupby(by=['participant_id'])\n",
    "# columns = ['avg_hr', 'std_hr', 'Sleep Stage Sum']\n",
    "# rhythm_7days = []\n",
    "# for group in grouped:\n",
    "    \n",
    "#     df = copy.deepcopy(group[1])\n",
    "#     ID = group[0]\n",
    "#     curr_fea_df = []\n",
    "    \n",
    "#     for col_val in columns:\n",
    "        \n",
    "#         curr_window = copy.deepcopy(df[[col_val,'hour']])\n",
    "        \n",
    "#         M10H = M10(curr_window, col_val, 'hour')\n",
    "#         L5H = L5(curr_window, col_val, 'hour')\n",
    "        \n",
    "#         AMP = (M10H-L5H)/(M10H+L5H)\n",
    "        \n",
    "#         DVT = deviation_from_template(curr_window, col_val, 'hour')\n",
    "        \n",
    "#         period_list = [8,16,20, 22, 27, 28, 32, 36, 64, 72, 128]\n",
    "        \n",
    "#         PSD = power_spectral_density(curr_window[col_val], period_list)\n",
    "        \n",
    "#         cosinor_value = fit_cosinor(curr_window, col_val, 'hour', period_list) \n",
    "        \n",
    "#         fea_dict = {'M10':[M10H],'L5':[L5H], 'AMP':[AMP]}\n",
    "        \n",
    "#         fea_dict.update(PSD)\n",
    "        \n",
    "#         fea_dict.update(cosinor_value)\n",
    "        \n",
    "#         fea_dict2 = {col_val+'_'+k: v for k,v in fea_dict.items()}\n",
    "        \n",
    "#         DVT = DVT.mean().to_dict()\n",
    "        \n",
    "#         fea_df = pd.DataFrame(data={**fea_dict2, **DVT})\n",
    "        \n",
    "#         # fea_df = pd.concat((fea_df, DVT), axis=1)\n",
    "        \n",
    "#         if len(curr_fea_df) == 0:\n",
    "#             curr_fea_df = fea_df\n",
    "#         else:\n",
    "#             curr_fea_df = pd.concat((curr_fea_df,fea_df), axis=1)\n",
    "#     curr_fea_df['ID'] = ID\n",
    "    \n",
    "#     if len(rhythm_7days) == 0:\n",
    "#         rhythm_7days = curr_fea_df\n",
    "#     else:\n",
    "#         rhythm_7days = pd.concat((rhythm_7days,curr_fea_df), axis=0) \n",
    "# rhythm_7days.reset_index(inplace=True, drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
